{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 05 - Analysis and Visualization\n",
                "\n",
                "This notebook provides comprehensive analysis and visualization of the trained LDA model.\n",
                "\n",
                "## Contents\n",
                "- Topic exploration (word clouds, top words)\n",
                "- pyLDAvis interactive visualization\n",
                "- Topic trends over time\n",
                "- Document similarity\n",
                "- Topic comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import required libraries\n",
                "import sys\n",
                "import pickle\n",
                "from pathlib import Path\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Add project root to path\n",
                "project_root = Path.cwd().parent\n",
                "if str(project_root) not in sys.path:\n",
                "    sys.path.insert(0, str(project_root))\n",
                "\n",
                "from src.config import get_settings\n",
                "from src.lda_model import LDATopicModel\n",
                "from src.analysis import TopicAnalyzer\n",
                "from src.visualizations import TopicVisualizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load settings\n",
                "settings = get_settings()\n",
                "\n",
                "# Load model\n",
                "print(\"Loading model...\")\n",
                "model = LDATopicModel(settings)\n",
                "model.load()\n",
                "\n",
                "print(f\"Loaded model with {model.model.num_topics} topics\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load processed data\n",
                "corpus_path = settings.processed_data_dir / settings.processed_corpus_file\n",
                "with open(corpus_path, 'rb') as f:\n",
                "    corpus_data = pickle.load(f)\n",
                "\n",
                "processed_docs = corpus_data['documents']\n",
                "df = corpus_data['dataframe']\n",
                "\n",
                "print(f\"Loaded {len(processed_docs):,} documents\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize analyzer and visualizer\n",
                "analyzer = TopicAnalyzer(model, settings)\n",
                "visualizer = TopicVisualizer(model, settings)\n",
                "\n",
                "# Set document data for analysis\n",
                "analyzer.set_document_data(df, tokens_column='tokens')\n",
                "\n",
                "print(\"Analyzer and Visualizer initialized\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Topic Overview"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display all topics\n",
                "topics = model.get_topics(num_words=10)\n",
                "\n",
                "print(f\"\\n{len(topics)} Topics:\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "for topic in topics:\n",
                "    print(f\"\\nTopic {topic.topic_id}: {', '.join(topic.top_words[:8])}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Topic prevalence\n",
                "prevalence = analyzer.compute_topic_prevalence()\n",
                "prevalence"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize prevalence\n",
                "fig = visualizer.plot_topic_prevalence(prevalence)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Word Clouds"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Word clouds for all topics\n",
                "fig = visualizer.plot_all_wordclouds(num_words=40, cols=3)\n",
                "\n",
                "# Save\n",
                "wc_path = settings.outputs_dir / 'wordclouds_all.png'\n",
                "fig.savefig(wc_path, dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"Saved to: {wc_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Individual topic word cloud\n",
                "TOPIC_TO_VIEW = 0  # Change this to view different topic\n",
                "\n",
                "fig = visualizer.plot_wordcloud(TOPIC_TO_VIEW, num_words=50)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. pyLDAvis Interactive Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create and display pyLDAvis\n",
                "import pyLDAvis\n",
                "import pyLDAvis.gensim_models\n",
                "\n",
                "# Enable notebook mode\n",
                "pyLDAvis.enable_notebook()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare visualization\n",
                "vis_data = visualizer.create_pyldavis(\n",
                "    processed_docs,\n",
                "    save_path=settings.outputs_dir / 'pyldavis.html'\n",
                ")\n",
                "\n",
                "print(f\"\\nSaved pyLDAvis to: {settings.outputs_dir / 'pyldavis.html'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display interactive visualization\n",
                "pyLDAvis.display(vis_data)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Topic Trends Over Time"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute topic trends by year\n",
                "if 'year' in df.columns:\n",
                "    trends = analyzer.compute_topic_trends(date_column='year', freq='Y')\n",
                "    \n",
                "    print(\"Topic trends computed\")\n",
                "    trends.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize trends\n",
                "if 'year' in df.columns:\n",
                "    fig = visualizer.plot_topic_trends(trends, date_column='_date')\n",
                "    \n",
                "    # Save\n",
                "    trends_path = settings.outputs_dir / 'topic_trends.png'\n",
                "    fig.savefig(trends_path, dpi=150, bbox_inches='tight')\n",
                "    plt.show()\n",
                "    \n",
                "    print(f\"Saved to: {trends_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Document Similarity Search"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find similar documents to a specific document\n",
                "DOCUMENT_INDEX = 0  # Change to explore different documents\n",
                "\n",
                "# Display the query document\n",
                "query_doc = df.iloc[DOCUMENT_INDEX]\n",
                "print(\"Query Document:\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"Title: {query_doc['title']}\")\n",
                "print(f\"\\nAbstract: {query_doc['abstract'][:300]}...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find similar documents\n",
                "similar_docs = analyzer.find_similar_documents(DOCUMENT_INDEX, top_n=5)\n",
                "\n",
                "print(\"\\nMost Similar Documents:\")\n",
                "print(\"-\" * 60)\n",
                "for i, (_, row) in enumerate(similar_docs.iterrows()):\n",
                "    print(f\"\\n{i+1}. (Similarity: {row['similarity']:.3f})\")\n",
                "    print(f\"   Title: {row['title'][:70]}...\" if len(row['title']) > 70 else f\"   Title: {row['title']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Topic Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare two topics\n",
                "TOPIC_A = 0\n",
                "TOPIC_B = 1\n",
                "\n",
                "fig = visualizer.plot_topic_comparison(TOPIC_A, TOPIC_B, num_words=12)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze topic overlap\n",
                "overlap = analyzer.get_topic_overlap(TOPIC_A, TOPIC_B, num_words=20)\n",
                "\n",
                "print(f\"Topic {TOPIC_A} vs Topic {TOPIC_B} Overlap Analysis:\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Jaccard Similarity: {overlap['jaccard_similarity']:.3f}\")\n",
                "print(f\"\\nShared words: {', '.join(overlap['shared_words'][:10])}\")\n",
                "print(f\"\\nUnique to Topic {TOPIC_A}: {', '.join(overlap['unique_to_a'][:5])}\")\n",
                "print(f\"Unique to Topic {TOPIC_B}: {', '.join(overlap['unique_to_b'][:5])}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Topic distance matrix\n",
                "distance_matrix = analyzer.compute_topic_distance_matrix()\n",
                "\n",
                "fig = visualizer.plot_topic_distance_heatmap(distance_matrix)\n",
                "\n",
                "# Save\n",
                "dist_path = settings.outputs_dir / 'topic_distances.png'\n",
                "fig.savefig(dist_path, dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"Saved to: {dist_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Documents by Topic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get documents dominated by a specific topic\n",
                "TOPIC_ID = 0\n",
                "\n",
                "topic_docs = analyzer.get_documents_by_topic(TOPIC_ID, min_probability=0.3, top_n=10)\n",
                "\n",
                "print(f\"\\nTop 10 Documents for Topic {TOPIC_ID}:\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "prob_col = f'topic_{TOPIC_ID}_prob'\n",
                "for i, (_, row) in enumerate(topic_docs.iterrows()):\n",
                "    print(f\"\\n{i+1}. (Prob: {row[prob_col]:.3f})\")\n",
                "    title = row['title']\n",
                "    print(f\"   {title[:75]}...\" if len(title) > 75 else f\"   {title}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Document-Topic Heatmap"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get topic matrix\n",
                "topic_matrix = model.get_document_topic_matrix(processed_docs, show_progress=False)\n",
                "\n",
                "# Plot heatmap for first 50 documents\n",
                "fig = visualizer.plot_document_topic_heatmap(topic_matrix, num_docs=50)\n",
                "\n",
                "# Save\n",
                "heatmap_path = settings.outputs_dir / 'doc_topic_heatmap.png'\n",
                "fig.savefig(heatmap_path, dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"Saved to: {heatmap_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Save All Visualizations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save all visualizations to outputs directory\n",
                "print(\"Saving all visualizations...\")\n",
                "\n",
                "viz_paths = visualizer.save_all_visualizations(\n",
                "    processed_docs,\n",
                "    topic_matrix,\n",
                "    prevalence,\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ All visualizations saved:\")\n",
                "for name, path in viz_paths.items():\n",
                "    print(f\"   - {name}: {path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"ANALYSIS AND VISUALIZATION COMPLETE\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "print(f\"\\nüìä Model: {model.model.num_topics} topics\")\n",
                "print(f\"üìà Coherence: {model.metadata.coherence_score:.4f}\")\n",
                "print(f\"üìö Documents: {len(processed_docs):,}\")\n",
                "\n",
                "print(f\"\\nüìÅ Output files saved to: {settings.outputs_dir}\")\n",
                "\n",
                "print(f\"\\nüöÄ Launch the dashboard with:\")\n",
                "print(f\"   streamlit run dashboard/app.py\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}