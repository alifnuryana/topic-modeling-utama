{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02 - Data Cleaning\n",
                "\n",
                "This notebook cleans the raw metadata based on EDA findings.\n",
                "\n",
                "## Cleaning Steps\n",
                "- Handle missing values\n",
                "- Remove duplicates\n",
                "- Standardize date formats\n",
                "- Validate and normalize text fields\n",
                "- Filter out unusable records"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import required libraries\n",
                "import sys\n",
                "from pathlib import Path\n",
                "import re\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Add project root to path\n",
                "project_root = Path.cwd().parent\n",
                "if str(project_root) not in sys.path:\n",
                "    sys.path.insert(0, str(project_root))\n",
                "\n",
                "from src.config import get_settings, ensure_directories"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load settings and data\n",
                "settings = get_settings()\n",
                "ensure_directories(settings)\n",
                "\n",
                "data_path = settings.raw_data_dir / settings.raw_metadata_file\n",
                "print(f\"Loading raw data from: {data_path}\")\n",
                "\n",
                "df = pd.read_csv(data_path)\n",
                "print(f\"Loaded {len(df):,} records\")\n",
                "print(f\"Columns: {list(df.columns)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initial state\n",
                "initial_count = len(df)\n",
                "print(f\"\\nInitial record count: {initial_count:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Remove Duplicates"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove exact duplicates\n",
                "before = len(df)\n",
                "df = df.drop_duplicates()\n",
                "after = len(df)\n",
                "print(f\"Removed {before - after:,} exact duplicates\")\n",
                "\n",
                "# Remove duplicate identifiers (keep first)\n",
                "before = len(df)\n",
                "df = df.drop_duplicates(subset=['identifier'], keep='first')\n",
                "after = len(df)\n",
                "print(f\"Removed {before - after:,} duplicate identifiers\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove duplicate titles (more aggressive - optional)\n",
                "# Uncomment if you want to remove records with duplicate titles\n",
                "\n",
                "# before = len(df)\n",
                "# df = df.drop_duplicates(subset=['title'], keep='first')\n",
                "# after = len(df)\n",
                "# print(f\"Removed {before - after:,} duplicate titles\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Handle Missing Values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check current missing values\n",
                "print(\"Current missing values:\")\n",
                "for col in df.columns:\n",
                "    missing = df[col].isna().sum()\n",
                "    if missing > 0:\n",
                "        print(f\"  {col}: {missing:,} ({missing/len(df)*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove records without title (essential field)\n",
                "before = len(df)\n",
                "df = df[df['title'].notna() & (df['title'].str.strip() != '')]\n",
                "after = len(df)\n",
                "print(f\"Removed {before - after:,} records without title\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove records without abstract (needed for topic modeling)\n",
                "before = len(df)\n",
                "df = df[df['abstract'].notna() & (df['abstract'].str.strip() != '')]\n",
                "after = len(df)\n",
                "print(f\"Removed {before - after:,} records without abstract\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fill missing values for non-essential fields\n",
                "df['authors'] = df['authors'].fillna('')\n",
                "df['subjects'] = df['subjects'].fillna('')\n",
                "df['publisher'] = df['publisher'].fillna('')\n",
                "df['types'] = df['types'].fillna('')\n",
                "df['language'] = df['language'].fillna('')\n",
                "df['source'] = df['source'].fillna('')\n",
                "\n",
                "print(\"Filled missing values for non-essential fields\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Standardize Date Format"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Parse and standardize dates\n",
                "def parse_date(date_str):\n",
                "    \"\"\"Parse various date formats and extract year.\"\"\"\n",
                "    if pd.isna(date_str) or date_str == '':\n",
                "        return None, None\n",
                "    \n",
                "    date_str = str(date_str).strip()\n",
                "    \n",
                "    # Try to parse as datetime\n",
                "    try:\n",
                "        parsed = pd.to_datetime(date_str)\n",
                "        return parsed, parsed.year\n",
                "    except:\n",
                "        pass\n",
                "    \n",
                "    # Extract year using regex\n",
                "    year_match = re.search(r'(19|20)\\d{2}', date_str)\n",
                "    if year_match:\n",
                "        year = int(year_match.group())\n",
                "        return pd.Timestamp(year=year, month=1, day=1), year\n",
                "    \n",
                "    return None, None\n",
                "\n",
                "# Apply parsing\n",
                "parsed_dates = df['date'].apply(parse_date)\n",
                "df['parsed_date'] = [d[0] for d in parsed_dates]\n",
                "df['year'] = [d[1] for d in parsed_dates]\n",
                "\n",
                "# Statistics\n",
                "valid_dates = df['year'].notna().sum()\n",
                "print(f\"Successfully parsed dates: {valid_dates:,} ({valid_dates/len(df)*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Year distribution\n",
                "print(\"\\nYear distribution:\")\n",
                "year_counts = df['year'].value_counts().sort_index()\n",
                "print(year_counts.tail(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Text Normalization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def normalize_text(text):\n",
                "    \"\"\"Normalize text field.\"\"\"\n",
                "    if pd.isna(text) or text == '':\n",
                "        return ''\n",
                "    \n",
                "    text = str(text)\n",
                "    \n",
                "    # Remove extra whitespace\n",
                "    text = re.sub(r'\\s+', ' ', text)\n",
                "    \n",
                "    # Remove leading/trailing whitespace\n",
                "    text = text.strip()\n",
                "    \n",
                "    # Remove control characters\n",
                "    text = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', text)\n",
                "    \n",
                "    return text\n",
                "\n",
                "# Apply normalization\n",
                "df['title'] = df['title'].apply(normalize_text)\n",
                "df['abstract'] = df['abstract'].apply(normalize_text)\n",
                "df['authors'] = df['authors'].apply(normalize_text)\n",
                "df['subjects'] = df['subjects'].apply(normalize_text)\n",
                "\n",
                "print(\"Applied text normalization to title, abstract, authors, subjects\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Filter Records by Abstract Length"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate word counts\n",
                "df['abstract_word_count'] = df['abstract'].str.split().str.len()\n",
                "\n",
                "print(\"Abstract word count statistics:\")\n",
                "print(df['abstract_word_count'].describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove very short abstracts\n",
                "MIN_ABSTRACT_WORDS = 20\n",
                "\n",
                "before = len(df)\n",
                "df = df[df['abstract_word_count'] >= MIN_ABSTRACT_WORDS]\n",
                "after = len(df)\n",
                "\n",
                "print(f\"Removed {before - after:,} records with abstract < {MIN_ABSTRACT_WORDS} words\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Final Cleanup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reset index\n",
                "df = df.reset_index(drop=True)\n",
                "\n",
                "# Select final columns\n",
                "final_columns = [\n",
                "    'identifier',\n",
                "    'title',\n",
                "    'abstract',\n",
                "    'authors',\n",
                "    'date',\n",
                "    'year',\n",
                "    'subjects',\n",
                "    'publisher',\n",
                "    'types',\n",
                "    'language',\n",
                "]\n",
                "\n",
                "# Keep only existing columns\n",
                "final_columns = [c for c in final_columns if c in df.columns]\n",
                "df_clean = df[final_columns].copy()\n",
                "\n",
                "print(f\"Final columns: {list(df_clean.columns)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"CLEANING SUMMARY\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"Initial records:  {initial_count:,}\")\n",
                "print(f\"Final records:    {len(df_clean):,}\")\n",
                "print(f\"Removed:          {initial_count - len(df_clean):,} ({(initial_count - len(df_clean))/initial_count*100:.1f}%)\")\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Cleaned Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save to processed directory\n",
                "output_path = settings.processed_data_dir / settings.clean_metadata_file\n",
                "\n",
                "df_clean.to_csv(output_path, index=False, encoding='utf-8')\n",
                "\n",
                "print(f\"\\nâœ… Saved cleaned data to: {output_path}\")\n",
                "print(f\"ðŸ“Š Total records: {len(df_clean):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preview cleaned data\n",
                "df_clean.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick stats\n",
                "print(\"\\nCleaned data statistics:\")\n",
                "print(\"-\" * 40)\n",
                "print(f\"Records: {len(df_clean):,}\")\n",
                "print(f\"Date range: {df_clean['year'].min():.0f} - {df_clean['year'].max():.0f}\")\n",
                "print(f\"Avg abstract words: {df_clean['abstract'].str.split().str.len().mean():.0f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"\\nðŸ‘‰ Next: Run 02b_eda_clean_data.ipynb to analyze the cleaned data\")\n",
                "print(f\"   Then: Run 03_preprocessing.ipynb for text preprocessing\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}