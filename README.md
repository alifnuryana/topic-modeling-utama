# Topic Modeling with LDA

A comprehensive Topic Modeling system using Latent Dirichlet Allocation (LDA) for analyzing academic paper metadata from the Widyatama University repository.

## ğŸ¯ Features

- **Data Collection**: OAI-PMH harvesting with cloudscraper protection
- **Indonesian NLP**: PySastrawi stemming, Indonesian stopwords
- **Topic Modeling**: LDA with coherence-based optimization
- **Interactive Dashboard**: Streamlit multi-page exploration
- **Comprehensive Analysis**: Trend analysis, document similarity, topic comparison

## ğŸ“ Project Structure

```
topic-modeling-utama/
â”œâ”€â”€ src/                      # Core Python modules
â”‚   â”œâ”€â”€ config.py             # Configuration settings
â”‚   â”œâ”€â”€ harvester.py          # OAI-PMH data collection
â”‚   â”œâ”€â”€ preprocessor.py       # Indonesian text preprocessing
â”‚   â”œâ”€â”€ lda_model.py          # LDA model training
â”‚   â”œâ”€â”€ analysis.py           # Analysis utilities
â”‚   â””â”€â”€ visualizations.py     # Visualization functions
â”œâ”€â”€ notebooks/                # Jupyter notebooks (pipeline)
â”‚   â”œâ”€â”€ 01_data_collection.ipynb
â”‚   â”œâ”€â”€ 01b_eda_raw_data.ipynb
â”‚   â”œâ”€â”€ 02_data_cleaning.ipynb
â”‚   â”œâ”€â”€ 02b_eda_clean_data.ipynb
â”‚   â”œâ”€â”€ 03_preprocessing.ipynb
â”‚   â”œâ”€â”€ 04_lda_modeling.ipynb
â”‚   â””â”€â”€ 05_analysis_visualization.ipynb
â”œâ”€â”€ dashboard/                # Streamlit dashboard
â”‚   â”œâ”€â”€ app.py                # Entry point
â”‚   â”œâ”€â”€ utils.py              # Utilities
â”‚   â”œâ”€â”€ pages/                # Dashboard pages
â”‚   â””â”€â”€ components/           # Reusable UI components
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Raw harvested data
â”‚   â””â”€â”€ processed/            # Cleaned and processed data
â”œâ”€â”€ models/                   # Trained LDA models
â””â”€â”€ outputs/                  # Generated visualizations
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
uv sync
```

### 2. Run the Pipeline

Execute notebooks in order:

1. **Data Collection** - `01_data_collection.ipynb`
   - Harvests metadata from repository

2. **EDA (Raw)** - `01b_eda_raw_data.ipynb`
   - Explores raw data quality

3. **Data Cleaning** - `02_data_cleaning.ipynb`
   - Cleans and validates data

4. **EDA (Clean)** - `02b_eda_clean_data.ipynb`
   - Analyzes cleaned data

5. **Preprocessing** - `03_preprocessing.ipynb`
   - Tokenization, stemming, phrase detection

6. **LDA Modeling** - `04_lda_modeling.ipynb`
   - Trains and optimizes LDA model

7. **Visualization** - `05_analysis_visualization.ipynb`
   - Generates all visualizations

### 3. Launch Dashboard

```bash
streamlit run dashboard/app.py
```

## ğŸ“Š Dashboard Pages

| Page | Description |
|------|-------------|
| ğŸ  **Home** | Overview and quick stats |
| ğŸ“Š **Topic Explorer** | Word clouds, top words, pyLDAvis |
| ğŸ“„ **Document Browser** | Search and filter documents |
| ğŸ” **Similarity Search** | Find similar documents |
| ğŸ“ˆ **Trend Analysis** | Topic evolution over time |
| ğŸ¯ **Topic Comparison** | Compare topics side-by-side |
| âš™ï¸ **Model Insights** | Model metrics and configuration |

## âš™ï¸ Configuration

Configuration is managed through `src/config.py`. Key settings:

```python
# OAI-PMH
oaipmh_endpoint = "https://repository.widyatama.ac.id/oai/request"

# LDA Model
lda_num_topics = 10
lda_passes = 15
lda_iterations = 400

# Preprocessing
use_stemming = True  # PySastrawi
use_bigrams = True
use_trigrams = True
```

Override via environment variables with `TM_` prefix:
```bash
export TM_LDA_NUM_TOPICS=15
```

## ğŸ“¦ Dependencies

- **Data**: pandas, numpy, sickle, cloudscraper
- **NLP**: gensim, nltk, PySastrawi, nlp-id
- **Visualization**: matplotlib, seaborn, plotly, wordcloud, pyLDAvis
- **Dashboard**: streamlit, streamlit-option-menu
- **Notebooks**: jupyter, ipywidgets
- **Config**: pydantic, pydantic-settings

## ğŸ“ License

MIT License
